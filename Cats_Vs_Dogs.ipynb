{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Cats_Vs_Dogs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ieDRfyxb1Hh",
        "outputId": "e66fa739-4b43-463a-9f2f-9059ca02e099"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbJOwkBuhKmp"
      },
      "source": [
        "#image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEKvVEu5cnHS"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest')\n",
        "\n",
        "\n",
        "img = load_img('/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/train/Cat/cat.201.jpg')\n",
        "\n",
        "x = img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Extra_2', save_prefix = 'cat', save_format = 'jpeg'):\n",
        "    i += 1\n",
        "    if i>20:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Duvg0KhXwH"
      },
      "source": [
        "#Training a small convnet from scratch: 80% accuracy in 40 lines of code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we_GCoBIf8LF"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Validation'\n",
        "\n",
        "nb_train_samples = 1000\n",
        "nb_validation_samples = 800\n",
        "epochs = 20\n",
        "batch_size = 8\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3), input_shape = input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OcLRa17qxnq",
        "outputId": "3a478b7b-77ca-4e65-d4f6-19f27037f27d"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs  = epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 383s 3s/step - loss: 0.6984 - accuracy: 0.5450 - val_loss: 0.6755 - val_accuracy: 0.5288\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 39s 315ms/step - loss: 0.6800 - accuracy: 0.5760 - val_loss: 0.6485 - val_accuracy: 0.5975\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 40s 318ms/step - loss: 0.6562 - accuracy: 0.6420 - val_loss: 0.6190 - val_accuracy: 0.6400\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.6463 - accuracy: 0.6260 - val_loss: 0.6215 - val_accuracy: 0.6388\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.6400 - accuracy: 0.6600 - val_loss: 0.5957 - val_accuracy: 0.6600\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 40s 316ms/step - loss: 0.6186 - accuracy: 0.6550 - val_loss: 0.6278 - val_accuracy: 0.6587\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 39s 315ms/step - loss: 0.6207 - accuracy: 0.6760 - val_loss: 0.6515 - val_accuracy: 0.6388\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.6107 - accuracy: 0.6940 - val_loss: 0.5676 - val_accuracy: 0.7075\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.5706 - accuracy: 0.7200 - val_loss: 0.5818 - val_accuracy: 0.7262\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 40s 320ms/step - loss: 0.5604 - accuracy: 0.7160 - val_loss: 0.5927 - val_accuracy: 0.6762\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 40s 318ms/step - loss: 0.5514 - accuracy: 0.7170 - val_loss: 1.0652 - val_accuracy: 0.6413\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.5477 - accuracy: 0.7340 - val_loss: 0.5606 - val_accuracy: 0.7100\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.5392 - accuracy: 0.7380 - val_loss: 1.3414 - val_accuracy: 0.6162\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.5230 - accuracy: 0.7590 - val_loss: 0.5683 - val_accuracy: 0.7163\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 40s 318ms/step - loss: 0.5264 - accuracy: 0.7510 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 40s 316ms/step - loss: 0.4964 - accuracy: 0.7730 - val_loss: 0.6530 - val_accuracy: 0.7138\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 40s 317ms/step - loss: 0.5299 - accuracy: 0.7760 - val_loss: 0.5459 - val_accuracy: 0.7425\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 39s 315ms/step - loss: 0.4862 - accuracy: 0.7770 - val_loss: 0.5198 - val_accuracy: 0.7487\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 40s 316ms/step - loss: 0.4935 - accuracy: 0.7730 - val_loss: 0.5796 - val_accuracy: 0.7375\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 40s 316ms/step - loss: 0.4633 - accuracy: 0.7840 - val_loss: 0.5636 - val_accuracy: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd9e0ca4c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW5TqGi_kHTo"
      },
      "source": [
        "#Using the bottleneck features of a pre-trained network: 90% accuracy in a minute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF8lNJ_qkIOD",
        "outputId": "4d8cb79c-45dd-4ce8-f241-e58f72155df6"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import applications\n",
        "import numpy as np\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "top_model_weights_path = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_fc_model.h5'\n",
        "train_data_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Validation'\n",
        "nb_train_samples = 1000\n",
        "nb_validation_samples = 800\n",
        "epochs = 25\n",
        "batch_size = 10\n",
        "def save_bottlebeck_features():\n",
        "    datagen = ImageDataGenerator(rescale = 1./255)\n",
        "    model = applications.VGG16(include_top = False, weights = 'imagenet')\n",
        "\n",
        "    generator = datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size = (img_width, img_height),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = None,\n",
        "        shuffle = False)\n",
        "    bottleneck_features_train = model.predict_generator(\n",
        "        generator, nb_train_samples//batch_size)\n",
        "    np.save(open('/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_features_train.npy','wb'),\n",
        "            bottleneck_features_train)\n",
        "    \n",
        "    generator  = datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size = (img_width, img_height),\n",
        "        batch_size = batch_size,\n",
        "        class_mode = None,\n",
        "        shuffle = False)\n",
        "    \n",
        "    bottleneck_features_validation = model.predict_generator(\n",
        "        generator, nb_validation_samples //batch_size)\n",
        "    np.save(open('/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_features_validation.npy', 'wb'),\n",
        "            bottleneck_features_validation)\n",
        "    \n",
        "def train_top_model():\n",
        "    train_data = np.load(open('/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_features_train.npy','rb'))\n",
        "    train_labels = np.array(\n",
        "        [0] * (nb_train_samples //2) + [1] * (nb_train_samples // 2))\n",
        "    \n",
        "    validation_data = np.load(open('/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_features_validation.npy','rb'))\n",
        "    validation_labels = np.array(\n",
        "        [0] * (nb_validation_samples//2) + [1] * (nb_validation_samples //2))\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape = train_data.shape[1:]))\n",
        "    model.add(Dense(256, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = 'rmsprop',\n",
        "                  loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    model.fit(train_data, train_labels,\n",
        "              epochs  = epochs,\n",
        "              batch_size = batch_size,\n",
        "              validation_data = (validation_data, validation_labels))\n",
        "    \n",
        "    model.save_weights(top_model_weights_path)\n",
        "    model.evaluate(validation_data, validation_labels)\n",
        "\n",
        "save_bottlebeck_features()\n",
        "train_top_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 3s 21ms/step - loss: 1.6401 - accuracy: 0.6482 - val_loss: 0.6825 - val_accuracy: 0.6988\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.4506 - accuracy: 0.8103 - val_loss: 0.3139 - val_accuracy: 0.8500\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.3421 - accuracy: 0.8480 - val_loss: 0.3100 - val_accuracy: 0.8788\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.2731 - accuracy: 0.8960 - val_loss: 0.3021 - val_accuracy: 0.8913\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.2556 - accuracy: 0.9175 - val_loss: 0.3344 - val_accuracy: 0.8700\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.1924 - accuracy: 0.9191 - val_loss: 0.3901 - val_accuracy: 0.8850\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.1635 - accuracy: 0.9424 - val_loss: 0.4394 - val_accuracy: 0.8750\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.1619 - accuracy: 0.9386 - val_loss: 0.4595 - val_accuracy: 0.8813\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.1588 - accuracy: 0.9369 - val_loss: 0.5063 - val_accuracy: 0.8763\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.1110 - accuracy: 0.9499 - val_loss: 0.5688 - val_accuracy: 0.8612\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0817 - accuracy: 0.9737 - val_loss: 0.5239 - val_accuracy: 0.8750\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0981 - accuracy: 0.9733 - val_loss: 0.5357 - val_accuracy: 0.8737\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0723 - accuracy: 0.9732 - val_loss: 0.7168 - val_accuracy: 0.8450\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0961 - accuracy: 0.9731 - val_loss: 0.7841 - val_accuracy: 0.8512\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0617 - accuracy: 0.9824 - val_loss: 0.9273 - val_accuracy: 0.8462\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0717 - accuracy: 0.9795 - val_loss: 0.7449 - val_accuracy: 0.8763\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.0736 - accuracy: 0.9813 - val_loss: 0.8630 - val_accuracy: 0.8687\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0354 - accuracy: 0.9876 - val_loss: 0.8041 - val_accuracy: 0.8775\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0878 - accuracy: 0.9757 - val_loss: 1.0824 - val_accuracy: 0.8388\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0424 - accuracy: 0.9843 - val_loss: 0.8443 - val_accuracy: 0.8737\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0240 - accuracy: 0.9909 - val_loss: 0.8409 - val_accuracy: 0.8625\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0226 - accuracy: 0.9905 - val_loss: 0.9332 - val_accuracy: 0.8700\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.0451 - accuracy: 0.9871 - val_loss: 0.9960 - val_accuracy: 0.8750\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0667 - accuracy: 0.9829 - val_loss: 0.9509 - val_accuracy: 0.8813\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.0098 - accuracy: 0.9950 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.9377 - accuracy: 0.8800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSEvETGyk5e8"
      },
      "source": [
        "train_data = np.load(open('/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_features_train.npy','rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwxiOdIglm4F",
        "outputId": "37872c61-58ea-41d6-dc58-b19d933e5423"
      },
      "source": [
        "train_data.shape[1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v0bSTGtlvZY"
      },
      "source": [
        "nb_train_samples = 1000\n",
        "\n",
        "train_labels = np.array(\n",
        "        [0] * (nb_train_samples //2) + [1] * (nb_train_samples // 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhwcpjGmsXQP"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwYav_QXso_q"
      },
      "source": [
        "[2] * (nb_train_samples //2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieL9ZECoztyE"
      },
      "source": [
        "#Fine-tuning the top layers of a a pre-trained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI7Bqq_k1c_R",
        "outputId": "65b6917b-f9b0-46d2-b05f-8da39bdc8a8a"
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "top_model_weights_path =  '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Save_File/bottleneck_fc_model.h5'\n",
        "img_width, img_height = 150,150\n",
        "\n",
        "train_data_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/Artificial Intelligence/Deep Learning/Keras/Cat Vs Dog/File/Validation'\n",
        "nb_train_samples = 1000\n",
        "nb_validation_samples = 800\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "model = applications.VGG16(weights = 'imagenet', include_top = False, input_shape = (150,150,3))\n",
        "print('Model Loaded.')\n",
        "\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape = model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "top_model.load_weights(top_model_weights_path)\n",
        "\n",
        "model = Model(inputs = model.input, outputs = top_model(model.output))\n",
        "\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable  = False\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer = optimizers.SGD(lr=1e-4, momentum = 0.9),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1. / 255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./ 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size  = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs = epochs,\n",
        "    validation_data = validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 895s 14s/step - loss: 0.2806 - accuracy: 0.9396 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 389s 6s/step - loss: 0.3837 - accuracy: 0.9305 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.4125 - accuracy: 0.9264 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.2912 - accuracy: 0.9352 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 375s 6s/step - loss: 0.3283 - accuracy: 0.9390 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 375s 6s/step - loss: 0.5434 - accuracy: 0.9167 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 375s 6s/step - loss: 0.5533 - accuracy: 0.9075 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4982 - accuracy: 0.9203 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.4098 - accuracy: 0.9202 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.4828 - accuracy: 0.9190 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.5669 - accuracy: 0.8975 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.4176 - accuracy: 0.9309 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.4466 - accuracy: 0.9222 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.4197 - accuracy: 0.9245 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.3860 - accuracy: 0.9342 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 371s 6s/step - loss: 0.4717 - accuracy: 0.9218 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 370s 6s/step - loss: 0.3897 - accuracy: 0.9254 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 371s 6s/step - loss: 0.3427 - accuracy: 0.9265 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4786 - accuracy: 0.9162 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.5100 - accuracy: 0.9258 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 377s 6s/step - loss: 0.2677 - accuracy: 0.9412 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 376s 6s/step - loss: 0.3490 - accuracy: 0.9309 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4570 - accuracy: 0.9120 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 370s 6s/step - loss: 0.3310 - accuracy: 0.9380 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4094 - accuracy: 0.9279 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4360 - accuracy: 0.9197 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 375s 6s/step - loss: 0.2885 - accuracy: 0.9318 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.3524 - accuracy: 0.9251 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.4448 - accuracy: 0.9228 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 376s 6s/step - loss: 0.3180 - accuracy: 0.9433 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 376s 6s/step - loss: 0.4174 - accuracy: 0.9144 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 375s 6s/step - loss: 0.2934 - accuracy: 0.9386 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 375s 6s/step - loss: 0.3786 - accuracy: 0.9301 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.4045 - accuracy: 0.9244 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.3361 - accuracy: 0.9394 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.3644 - accuracy: 0.9247 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.5026 - accuracy: 0.8973 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4401 - accuracy: 0.9210 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.3920 - accuracy: 0.9203 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.3812 - accuracy: 0.9051 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.3906 - accuracy: 0.9395 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4230 - accuracy: 0.9293 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.5529 - accuracy: 0.9060 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.4217 - accuracy: 0.9262 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.3884 - accuracy: 0.9267 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.4833 - accuracy: 0.9210 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 372s 6s/step - loss: 0.3459 - accuracy: 0.9205 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 373s 6s/step - loss: 0.2582 - accuracy: 0.9338 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.5294 - accuracy: 0.9215 - val_loss: 0.9377 - val_accuracy: 0.8800\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 374s 6s/step - loss: 0.3438 - accuracy: 0.9329 - val_loss: 0.9377 - val_accuracy: 0.8800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0953cfab50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    }
  ]
}